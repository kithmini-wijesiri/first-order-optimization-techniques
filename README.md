# first-order-optimization-methods
Gradient descent and Newton's method are two commonly used optimization algorithms in machine learning and computational chemistry. Both methods seek to find the minimum of a function, which is often a cost function that measures the discrepancy between model predictions and observed data
